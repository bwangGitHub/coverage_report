\section{Related Work}
\label{sec:related}
Most previous work considered correlation of code coverage criteria and ability of finding number of faults. To determine the fault detection ability researches manually inserted known faults to programs, either previous fixed bugs or syntactic change, then measure the number of seeded faults a test suite can detect, which is essentially the same as mutation testing. Budd et al. proved mutation testing score is a stronger metric compare to other coverage criteria for test suite evaluation. Li et al, compared three code coverage criteria(edge pair, all use, prime path) with mutation testing, found that mutation testing is the best in detecting hand seeded faults in small programs. Despite the studies did not use large-scale SUTs, with the methodologies that minimise the bias, it is highly possible that mutation testing is better at evaluating test suites.

Wong et al.ï½ž\cite{wong1994effect} investigated correlation between fault detection effectiveness and block coverage and correlation between fault detection effectiveness and size. They found that there is a correlation between block coverage and fault detection effectiveness. Also correlation between block coverage and fault detection effectiveness is higher than correlation between size and fault detection effectiveness. For this study, they believe that increasing the number of test cases in a test suite without increasing its coverage does not increase fault detection effectiveness.

Hutchins et al.~\cite{hutchins1994experiments} 

Andrew et al.~\cite{andrews2006using} studied behaviour of random selecting test suites and test suites constructed by adding test cases to improve test coverage, that is for the latter test suite if a test case does not increase coverage for a test suite, it is discarded and a new test case is selected. They found that for test suites with the same size, test suites consider coverage results better test effectiveness. Indirectly, it is saying there is a correlation between test effectiveness and coverage.

A study by Namin et al.~\cite{namin2009influence} claimed that both coverage and size have effect on test suite effectiveness. They found a non-linear relationship between test suite size, coverage and test suite effectiveness. They introduced a maths model (log(size) + coverage) which they believed can be used to predict the test suite effectiveness.

Cai et al.~\cite{cai2005effect} investigated relationship between test effectiveness and coverage metrics under different test profile: whole test set, functional test, random test, normal test, exceptional test. They found that for exceptional test, there is a significant correlation between test effectiveness and code coverage. There is no correlation for normal test. There is moderate correlation for functional and random test.


Gligoric et al.~\cite{gligoric2013comparing} measured both Kendall and Pearson to examine correlations to mutation kill for a set of criteria, Their work considers 15 Java programs and 11 C programs, selected not randomly but primarily from container classes used in previous studies and the classic Siemens subjects. Their larger projects (JodaTime, JFreeChart, SQLLite, YAFFS2) were chosen opportunistically. The study suggested that the correlation between coverage and effectiveness in real systems
is largely due to the correlation between coverage and size; it also suggested that results from automatically generated and manually generated suites do not generalize to each other.

Gopinath et al.~\cite{gopinath2014code} measured mutation score and coverage for more than 200 programs for their master suite and automatically generated test suites. They found there is correlation between coverage criteria and fault detection effectiveness for master suites and automatically generated suites. The correlation for master suite is stronger compare to automatically generated suites. They also claim that adding automatically generated suites to master suite does not necessarily increase test effectiveness. So size of test suite is not strongly correlated with effectiveness. (This is Alex work, the other paper we wanted to replicate)

This replication study is about a resent work from Inozemtseva et al.~\cite{inozemtseva2014coverage}. They studied correlation between different coverage and test effectiveness.

Unlike ealier studies which most of them used mutation testing score directly as effectiveness of fault detection. Inozemtseva et al.~\cite{inozemtseva2014coverage} defined two effectiveness measures, \textit{raw effectiveness measurement} and \textit{normalised effectiveness measurement}. "The raw kill score is the number of mutants a test suite detected divided by the total number of
non-equivalent mutants that were generated for the subject program under test."~\cite{inozemtseva2014coverage}. "The normalized effectiveness measurement is the number of mutants a test suite detected divided by the number of non-equivalent mutants it covers."~\cite{inozemtseva2014coverage}. A test suite cover the mutant means test cases in the test suite execute the mutated line of code. Or the mutant can be detected by the test suite. 

The reason to introduce this normalised effectiveness is that when size of test suite is controlled, there are limited lines of code and mutants it covers. Authors are more interested in effectiveness relative to the test suite itself. For example, test suite A kills 10 mutants and test suite B kills 100 mutants, for raw effectiveness suite B is certainly higher. If suite A only has 12 covered non-equivalent mutants and suite B has 200, suite A will have a higher normalised effectiveness than suite B. The definition of normalised effectiveness captures the idea that an effective suite is very good at finding faults with in the code that it runs.

The result of Inozemtseva et al.'s work is that when test suite size is not controlled, there is moderate to high correlation between all code coverage criteria and effectiveness; when test suite size is controlled, there is low to moderate correlation between all coverage types and effectiveness. Also saying size is a correlated with effectiveness.

As above studies show, most studies claim that there is some relationship between coverage, size and test effectiveness. But they do not agree to each other about how strong the relationship is.